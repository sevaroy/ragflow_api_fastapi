#!/usr/bin/env python3
"""
æ–¹æ³•2 é‹ä½œæ–¹å¼æ¼”ç¤º
è©³ç´°å±•ç¤ºç¤ºä¾‹æ•¸æ“šç”Ÿæˆå’Œå„€è¡¨æ¿å•Ÿå‹•çš„å®Œæ•´æµç¨‹
"""

import os
import json
import subprocess
import sys
from datetime import datetime
from pathlib import Path

def step1_generate_sample_data():
    """æ­¥é©Ÿ1: ç”Ÿæˆç¤ºä¾‹æ•¸æ“šçš„è©³ç´°éç¨‹"""
    print("ğŸ¯ æ­¥é©Ÿ1: ç”Ÿæˆç¤ºä¾‹ DeepEval æ•¸æ“š")
    print("=" * 50)
    
    print("ğŸ“ é€™å€‹æ­¥é©Ÿæœƒåšä»€éº¼:")
    print("   1. å‰µå»ºæ³•å¾‹ç›¸é—œçš„æ¸¬è©¦å•é¡Œ")
    print("   2. ç”Ÿæˆå°æ‡‰çš„æ¨™æº–ç­”æ¡ˆ")
    print("   3. æ¨¡æ“¬ AI ç³»çµ±çš„å¯¦éš›å›ç­”")
    print("   4. è¨ˆç®—å„é …è©•ä¼°æŒ‡æ¨™åˆ†æ•¸")
    print("   5. åˆ¤æ–·æ¯å€‹æ¡ˆä¾‹æ˜¯å¦é€šéé–¾å€¼")
    print("   6. ä¿å­˜ç‚º JSON æ ¼å¼æ–‡ä»¶")
    
    print("\nğŸ”§ æ•¸æ“šç”Ÿæˆé‚è¼¯:")
    print("   â€¢ å•é¡Œåº«: 15å€‹æ³•å¾‹å°ˆæ¥­å•é¡Œ")
    print("   â€¢ ç­”æ¡ˆåº«: 5å€‹æ¨™æº–æ³•å¾‹ç­”æ¡ˆ")
    print("   â€¢ è©•ä¼°æŒ‡æ¨™: 6å€‹æ ¸å¿ƒæŒ‡æ¨™")
    print("   â€¢ åˆ†æ•¸ç¯„åœ: 0.1 - 0.99")
    print("   â€¢ é€šéæ¨™æº–: åŸºæ–¼é è¨­é–¾å€¼")
    
    # å¯¦éš›åŸ·è¡Œæ•¸æ“šç”Ÿæˆ
    print("\nğŸš€ é–‹å§‹ç”Ÿæˆæ•¸æ“š...")
    
    try:
        # å°å…¥ç”Ÿæˆå‡½æ•¸
        from generate_sample_data import generate_sample_evaluation_data, generate_summary_data
        
        # ç”Ÿæˆ20å€‹æ¸¬è©¦æ¡ˆä¾‹
        num_cases = 20
        print(f"ğŸ“Š ç”Ÿæˆ {num_cases} å€‹æ¸¬è©¦æ¡ˆä¾‹...")
        
        results = generate_sample_evaluation_data(num_cases)
        summary = generate_summary_data(results)
        
        # ä¿å­˜æ–‡ä»¶
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        results_file = f"demo_evaluation_results_{timestamp}.json"
        summary_file = f"demo_evaluation_summary_{timestamp}.json"
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… è©³ç´°çµæœ: {results_file}")
        print(f"âœ… æ‘˜è¦æ•¸æ“š: {summary_file}")
        
        # é¡¯ç¤ºç”Ÿæˆçš„æ•¸æ“šçµ±è¨ˆ
        passed_count = sum(1 for r in results if r['passed'])
        pass_rate = passed_count / num_cases * 100
        avg_score = sum(r['overall_score'] for r in results) / num_cases
        
        print(f"\nğŸ“ˆ ç”Ÿæˆæ•¸æ“šçµ±è¨ˆ:")
        print(f"   ç¸½æ¡ˆä¾‹æ•¸: {num_cases}")
        print(f"   é€šéæ¡ˆä¾‹: {passed_count}")
        print(f"   é€šéç‡: {pass_rate:.1f}%")
        print(f"   å¹³å‡åˆ†æ•¸: {avg_score:.3f}")
        
        # é¡¯ç¤ºç¤ºä¾‹æ•¸æ“šçµæ§‹
        print(f"\nğŸ“‹ æ•¸æ“šçµæ§‹ç¤ºä¾‹:")
        example = results[0]
        print(f"   æ¸¬è©¦ID: {example['test_case_id']}")
        print(f"   å•é¡Œ: {example['question'][:50]}...")
        print(f"   æ•´é«”åˆ†æ•¸: {example['overall_score']}")
        print(f"   æ˜¯å¦é€šé: {example['passed']}")
        print(f"   æŒ‡æ¨™æ•¸é‡: {len(example['metrics_scores'])}")
        
        return results_file, summary_file
        
    except Exception as e:
        print(f"âŒ æ•¸æ“šç”Ÿæˆå¤±æ•—: {e}")
        return None, None

def step2_analyze_generated_data(results_file):
    """æ­¥é©Ÿ2: åˆ†æç”Ÿæˆçš„æ•¸æ“š"""
    print("\nğŸ” æ­¥é©Ÿ2: åˆ†æç”Ÿæˆçš„æ•¸æ“š")
    print("=" * 50)
    
    if not results_file or not os.path.exists(results_file):
        print("âŒ æ²’æœ‰æ‰¾åˆ°ç”Ÿæˆçš„æ•¸æ“šæ–‡ä»¶")
        return
    
    try:
        with open(results_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"ğŸ“Š æ•¸æ“šæ–‡ä»¶åˆ†æ: {results_file}")
        print(f"   æ–‡ä»¶å¤§å°: {os.path.getsize(results_file)} bytes")
        print(f"   æ•¸æ“šæ¢ç›®: {len(data)} å€‹")
        
        # åˆ†ææŒ‡æ¨™åˆ†å¸ƒ
        metrics = ['answer_relevancy', 'faithfulness', 'contextual_precision', 
                  'contextual_recall', 'hallucination', 'bias']
        
        print(f"\nğŸ“‹ æŒ‡æ¨™åˆ†æ•¸åˆ†å¸ƒ:")
        for metric in metrics:
            scores = [item['metrics_scores'][metric] for item in data if metric in item['metrics_scores']]
            if scores:
                avg_score = sum(scores) / len(scores)
                min_score = min(scores)
                max_score = max(scores)
                print(f"   {metric:20}: å¹³å‡ {avg_score:.3f} (ç¯„åœ: {min_score:.3f} - {max_score:.3f})")
        
        # åˆ†æé€šé/å¤±æ•—åˆ†å¸ƒ
        passed_cases = [item for item in data if item['passed']]
        failed_cases = [item for item in data if not item['passed']]
        
        print(f"\nâœ… é€šéæ¡ˆä¾‹åˆ†æ:")
        if passed_cases:
            avg_passed_score = sum(item['overall_score'] for item in passed_cases) / len(passed_cases)
            print(f"   æ•¸é‡: {len(passed_cases)}")
            print(f"   å¹³å‡åˆ†æ•¸: {avg_passed_score:.3f}")
        
        print(f"\nâŒ å¤±æ•—æ¡ˆä¾‹åˆ†æ:")
        if failed_cases:
            avg_failed_score = sum(item['overall_score'] for item in failed_cases) / len(failed_cases)
            print(f"   æ•¸é‡: {len(failed_cases)}")
            print(f"   å¹³å‡åˆ†æ•¸: {avg_failed_score:.3f}")
            
            # é¡¯ç¤ºå¤±æ•—åŸå› 
            print(f"   ä¸»è¦å¤±æ•—åŸå› :")
            for item in failed_cases[:3]:  # é¡¯ç¤ºå‰3å€‹å¤±æ•—æ¡ˆä¾‹
                failing_metrics = []
                for metric, score in item['metrics_scores'].items():
                    if metric in ['hallucination', 'bias']:
                        if score > 0.3:  # è² å‘æŒ‡æ¨™é–¾å€¼
                            failing_metrics.append(f"{metric}({score:.3f})")
                    else:
                        if score < 0.7:  # æ­£å‘æŒ‡æ¨™é–¾å€¼
                            failing_metrics.append(f"{metric}({score:.3f})")
                
                if failing_metrics:
                    print(f"     {item['test_case_id']}: {', '.join(failing_metrics)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•¸æ“šåˆ†æå¤±æ•—: {e}")
        return False

def step3_prepare_dashboard():
    """æ­¥é©Ÿ3: æº–å‚™å„€è¡¨æ¿ç’°å¢ƒ"""
    print("\nğŸ› ï¸ æ­¥é©Ÿ3: æº–å‚™å„€è¡¨æ¿ç’°å¢ƒ")
    print("=" * 50)
    
    print("ğŸ” æª¢æŸ¥ä¾è³´åŒ…...")
    required_packages = ['streamlit', 'plotly', 'pandas']
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"   âœ… {package}")
        except ImportError:
            print(f"   âŒ {package} - æœªå®‰è£")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nğŸ“¦ éœ€è¦å®‰è£ç¼ºå°‘çš„ä¾è³´: {', '.join(missing_packages)}")
        install_choice = input("æ˜¯å¦ç¾åœ¨å®‰è£? [y/N]: ").strip().lower()
        
        if install_choice in ['y', 'yes']:
            try:
                subprocess.check_call([
                    sys.executable, "-m", "pip", "install"
                ] + missing_packages)
                print("âœ… ä¾è³´å®‰è£æˆåŠŸ")
            except subprocess.CalledProcessError as e:
                print(f"âŒ ä¾è³´å®‰è£å¤±æ•—: {e}")
                return False
        else:
            print("âš ï¸ è·³éä¾è³´å®‰è£ï¼Œå„€è¡¨æ¿å¯èƒ½ç„¡æ³•æ­£å¸¸é‹è¡Œ")
    
    # æª¢æŸ¥å„€è¡¨æ¿æ–‡ä»¶
    print(f"\nğŸ“ æª¢æŸ¥å„€è¡¨æ¿æ–‡ä»¶...")
    dashboard_files = [
        'deepeval_dashboard.py',
        'run_dashboard.py'
    ]
    
    for file in dashboard_files:
        if os.path.exists(file):
            print(f"   âœ… {file}")
        else:
            print(f"   âŒ {file} - æ–‡ä»¶ä¸å­˜åœ¨")
            return False
    
    print("âœ… å„€è¡¨æ¿ç’°å¢ƒæº–å‚™å®Œæˆ")
    return True

def step4_launch_dashboard():
    """æ­¥é©Ÿ4: å•Ÿå‹•å„€è¡¨æ¿"""
    print("\nğŸš€ æ­¥é©Ÿ4: å•Ÿå‹• Streamlit å„€è¡¨æ¿")
    print("=" * 50)
    
    print("ğŸŒ å„€è¡¨æ¿å•Ÿå‹•ä¿¡æ¯:")
    print("   URL: http://localhost:8501")
    print("   åŠŸèƒ½: DeepEval è©•ä¼°çµæœè¦–è¦ºåŒ–")
    print("   æ“ä½œ: åœ¨å´é‚Šæ¬„è¼‰å…¥ç”Ÿæˆçš„ JSON æ–‡ä»¶")
    
    print(f"\nğŸ“‹ å¯è¼‰å…¥çš„æ–‡ä»¶:")
    json_files = [f for f in os.listdir('.') if f.endswith('.json') and 'evaluation' in f]
    for i, file in enumerate(json_files, 1):
        file_size = os.path.getsize(file)
        print(f"   {i}. {file} ({file_size} bytes)")
    
    print(f"\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("   1. å„€è¡¨æ¿å•Ÿå‹•å¾Œï¼Œåœ¨å´é‚Šæ¬„é¸æ“‡ JSON æ–‡ä»¶")
    print("   2. æŸ¥çœ‹æ•´é«”è¡¨ç¾æ‘˜è¦")
    print("   3. åˆ†æè©•ä¼°æŒ‡æ¨™è©³æƒ…")
    print("   4. ç€è¦½è©³ç´°è©•ä¼°çµæœ")
    print("   5. å°å‡ºåˆ†æå ±å‘Š")
    
    launch_choice = input("\næ˜¯å¦ç¾åœ¨å•Ÿå‹•å„€è¡¨æ¿? [y/N]: ").strip().lower()
    
    if launch_choice in ['y', 'yes']:
        print("ğŸš€ æ­£åœ¨å•Ÿå‹•å„€è¡¨æ¿...")
        print("   æŒ‰ Ctrl+C åœæ­¢æœå‹™")
        print("-" * 50)
        
        try:
            subprocess.run([
                sys.executable, "-m", "streamlit", "run", 
                "deepeval_dashboard.py",
                "--server.port", "8501",
                "--server.address", "localhost"
            ])
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å„€è¡¨æ¿å·²åœæ­¢")
        except Exception as e:
            print(f"âŒ å•Ÿå‹•å¤±æ•—: {e}")
    else:
        print("ğŸ’¡ ä½ å¯ä»¥ç¨å¾Œæ‰‹å‹•å•Ÿå‹•:")
        print("   python3 run_dashboard.py")
        print("   æˆ–")
        print("   streamlit run deepeval_dashboard.py")

def main():
    """ä¸»å‡½æ•¸ - å®Œæ•´æ¼”ç¤ºæ–¹æ³•2çš„é‹ä½œæ–¹å¼"""
    print("ğŸ¯ æ–¹æ³•2 é‹ä½œæ–¹å¼å®Œæ•´æ¼”ç¤º")
    print("=" * 60)
    print("é€™å€‹æ¼”ç¤ºå°‡å±•ç¤ºå¦‚ä½•:")
    print("1. ç”Ÿæˆç¤ºä¾‹ DeepEval æ•¸æ“š")
    print("2. åˆ†æç”Ÿæˆçš„æ•¸æ“šçµæ§‹")
    print("3. æº–å‚™å„€è¡¨æ¿ç’°å¢ƒ")
    print("4. å•Ÿå‹• Streamlit å„€è¡¨æ¿")
    print("=" * 60)
    
    # æ­¥é©Ÿ1: ç”Ÿæˆç¤ºä¾‹æ•¸æ“š
    results_file, summary_file = step1_generate_sample_data()
    
    if not results_file:
        print("âŒ æ•¸æ“šç”Ÿæˆå¤±æ•—ï¼Œç„¡æ³•ç¹¼çºŒ")
        return
    
    # æ­¥é©Ÿ2: åˆ†æç”Ÿæˆçš„æ•¸æ“š
    if not step2_analyze_generated_data(results_file):
        print("âš ï¸ æ•¸æ“šåˆ†æå¤±æ•—ï¼Œä½†å¯ä»¥ç¹¼çºŒ")
    
    # æ­¥é©Ÿ3: æº–å‚™å„€è¡¨æ¿ç’°å¢ƒ
    if not step3_prepare_dashboard():
        print("âŒ å„€è¡¨æ¿ç’°å¢ƒæº–å‚™å¤±æ•—")
        return
    
    # æ­¥é©Ÿ4: å•Ÿå‹•å„€è¡¨æ¿
    step4_launch_dashboard()
    
    print(f"\nğŸ‰ æ–¹æ³•2 æ¼”ç¤ºå®Œæˆï¼")
    print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"   - {results_file}")
    print(f"   - {summary_file}")

if __name__ == "__main__":
    main()